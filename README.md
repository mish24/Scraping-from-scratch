# Scraping-from-scratch
Trying to make my own web-scraper from the scratch just using urllib.
There are three python files - for housekeeping, for finding the links and for crawling them.
This uses the concept of multithreading so that many spiders crawl a single queue (of links) and move them to other folder of scraped links.
PS: The files are converted to sets for making the scraping process fast.
